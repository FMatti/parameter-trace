\documentclass[12pt]{article}

\usepackage{stylesheet}

% to speed up compilation speed a bit while drafting
\pdfcompresslevel=0
\pdfobjcompresslevel=0

\title{Randomized trace estimation for parameter-dependent matrices applied to spectral density approximation}

\begin{document}

\maketitle

%\todo{
%\begin{itemize}
%    \item Unify index notation
%    \item Double-check proofs
%    \item Add all references
%    \item Run numerical experiments 
%    \item Write introduction, abstract, and discussion
%    \item ArXiv HTML support (check if packages)
%\end{itemize}
%}

%\todo{
%    \tableofcontents
%}

\begin{abstract}
    Stochastic trace estimators are a family of well established techniques for approximating the trace of constant matrices. Oftentimes the matrix whose trace we aim to approximate continuously depends on a real parameter $t \in [a,b]$. This is for example the case when approximating the spectral density of a matrix or computing partition functions of quantum systems. Clearly, we could separately approximate the traces of the constant matrices $\mtx{B}(t_1), \dots, \mtx{B}(t_m)$ at the fixed values $t_1, \dots, t_m \in [a, b]$. However, this approach does not scale well if $m$ is large. We analyze three trace estimators for constant matrices -- the Girard-Hutchinson, Nyström, and Nyström++ estimators -- when they are applied to parameter-dependent matrices with the same randomization reused for all values of the parameter $t$. We show that all of these estimators closely match their corresponding error guarantees for constant matrices. In particular, for the Nyström++ method, we can guarantee an error of at most $\varepsilon$ by computing the estimate with just $\mathcal{O}(\varepsilon^{-1})$ random vectors, independent of what structure the symmetric positive semi-definite matrix $\mtx{B}(t)$ has. We employ these trace estimators to improve upon a technique for approximating the spectral density of a matrix and provide a detailed analysis of the resulting method. Finally, we confirm our theoretical developments in multiple numerical experiments.
\end{abstract}

\textcolor{red}{TODO for Fabio:
\begin{itemize}
 \item It is not great that the references occupy so much space (more than 4 pages); consider using a more condensed style. The paper needs to get strictly below 30 pages prior to submission. \textcolor{green}{Journal abbreviations, max 2 authors, omit superfluous fields $\to$ 3 pages.}
 Journal abbreviations and removing superfluous fields is good. max 2 authors is not coming in math, please reverse this. \textcolor{green}{Done.} The text style is a bit too generous but no need to change this now. \textcolor{green}{Ok! Let's talk about it at some point.}
\end{itemize}
}
\color{blue}
\input{intro.tex}
\input{analysis.tex}
\input{spectraldensity.tex}
%\input{numresults.tex}




\section{Conclusion}
\label{sec:conclusion}

\todo{
\begin{itemize}
    \item Robustness (can choose $m$ and $n_{\mtx{\Omega}}$, $n_{\mtx{\Psi}}$ as large as one wants, and not break algorithm, unlike Krylov-aware Lanczos)
\end{itemize}
}

\paragraph{Acknowledgements.} The authors gratefully acknowledge the help of Lin Lin in reproducing the example in \refsec{subsec:hamiltonian}. They thank David Persson for many enlightening discussions relating the proofs in \refsec{subsec:nystrom-pp}.

\printbibliography

\appendix

\section{Moment bounds for non-standard Gaussian random vectors and matrices}

The goal of this section is to establish moment bounds for $\lVert \mtx{A} \mtx{\Omega} \rVert _2^2$ with a fixed matrix $\mtx{A}$ and a Gaussian random matrix $\mtx{\Omega}$. These bounds are needed in the proof of \reflem{lem:nystrom}, but may also be of independent interest. For reasons which will become clear in the proof of the final and most interesting of these lemmas (\reflem{lem:nystrom}), we will need to bound $\mathbb{E}^{\sfrac{p}{2}}\left[\lVert \mtx{A} \mtx{\Omega} \rVert _2^2 \right]$ for a constant matrix $\mtx{A} \in \mathbb{R}^{m \times m}$ and a standard Gaussian random matrix $\mtx{\Omega} \in \mathbb{R}^{m \times k}$. The corresponding result for the Frobenius norm $\mathbb{E}^{\sfrac{p}{2}}\left[\lVert \mtx{A} \mtx{\Omega} \rVert _F^2 \right]$ has already been shown in \cite[Lemma 3]{kressner-2024-randomized-lowrank}. Several ways of separately bounding the spectral norm moments of the Wishart matrix $\mtx{\Omega} \mtx{\Omega}^{\top}$, i.e. when $\mtx{A} = \mtx{I}_m$ already exist, however, all of them are not sufficient for our purposes because they scale with $m$ \cite{chen-2005-condition-numbers, edelman-1988-eigenvalues-condition, james-1964-distributions-matrix}. In \cite[Lemma B.1]{tropp-2023-randomized-algorithms} a bound is achieved for $p = 2$ and $p = 4$. We will now generalize this result for arbitrary $p \in \mathbb{N}$. To do so, we first show the bound for Gaussian random vectors and then extend it to Gaussian random matrices in \reflem{lem:spectral-norm-moment}.


\textcolor{red}{??? Need to check carefully that this result is not known ???} \textcolor{green}{I haven't found anything so far. The fact that also Bujanović/Grubišić/Kressner/Lam in Lemma 20 use a very similar technique, but merely to bound $\Gamma(\frac{p+1}{2})$ makes me suspect there's not much, except for Stirling approximation at the cost of some simplicity. Will keep investigating.}

\begin{lemma}{Moment bound of $\chi^2$-random variable}{gamma}
    Let $X$ follow a $\chi^2$ distribution with $k \in \mathbb{N}$ degrees of freedom. Then for all $p \in \mathbb{N}$ it holds
    \begin{equation}
        \mathbb{E}^{\sfrac{p}{2}}[X] \leq k + p
        %\frac{\Gamma(\frac{k + p}{2})}{\Gamma(\frac{k}{2})} \leq \left( \frac{k + p}{2} \right)^{\sfrac{p}{2}}.
    \end{equation}
\end{lemma}

\begin{proof}
    From \cite[Theorem 3.3.2]{hogg-2013-introduction-mathematical} we know
    \begin{equation}
        \mathbb{E}^{\sfrac{p}{2}}[X] = 2 \left( \frac{\Gamma(\frac{k + p}{2})}{\Gamma(\frac{k}{2})} \right)^{\sfrac{2}{p}}.
    \end{equation}
    We first treat the case $k=p=1$, for which indeed
    \begin{equation}
        2 \left( \frac{\Gamma(\frac{1+1}{2})}{\Gamma(\frac{1}{2})} \right)^2 = \frac{2}{\pi} \leq 2 = 1 + 1
    \end{equation}
    So we now assume $k + p \geq 3$. We can use a telescoping product and the property $\Gamma(z+1)/\Gamma(z) = z$ to bound
    \begin{align}
        \frac{\Gamma(\frac{k + p}{2})}{\Gamma(\frac{k}{2})} 
        &= \frac{\Gamma(\frac{k}{2} + 1)}{\Gamma(\frac{k}{2})} \frac{\Gamma(\frac{k}{2} + 2)}{\Gamma(\frac{k}{2} + 1)} \cdots \frac{\Gamma(\frac{k}{2} + \lfloor \frac{p}{2} \rfloor)}{\Gamma(\frac{k}{2} + \lfloor \frac{p}{2} \rfloor - 1)} \frac{\Gamma( \frac{k + p}{2})}{\Gamma(\frac{k}{2} + \lfloor \frac{p}{2} \rfloor)} \notag \\
        &= \left(\frac{k}{2}\right) \left(\frac{k}{2} + 1\right) \cdots \left( \frac{k}{2} + \bigg\lfloor \frac{p}{2} \bigg\rfloor - 1 \right) \frac{\Gamma( \frac{k + p}{2})}{\Gamma(\frac{k}{2} + \lfloor \frac{p}{2} \rfloor)} \notag \\
        &\leq \left(\frac{k}{2} + \bigg\lfloor \frac{p}{2} \bigg\rfloor - 1\right)^{\lfloor \sfrac{p}{2} \rfloor} \frac{\Gamma( \frac{k + p}{2})}{\Gamma(\frac{k}{2} + \lfloor \frac{p}{2} \rfloor)}
    \end{align}
    If $p$ is even, then $\lfloor p/2 \rfloor = p/2$ and hence
    \begin{equation}
        \frac{\Gamma(\frac{k + p}{2})}{\Gamma(\frac{k}{2})} 
        \leq \left( \frac{k + p}{2} - 1 \right)^{\sfrac{p}{2}}
        \leq \left( \frac{k + p}{2}\right)^{\sfrac{p}{2}}.
    \end{equation}
    If $p$ is odd, then $\lfloor p/2 \rfloor = (p - 1)/2$, from which follows with Gautschi's inequality \cite{kershaw-1983-extensions-gautschi}
    \begin{equation}
        \frac{\Gamma(\frac{k + p}{2})}{\Gamma(\frac{k}{2})}
        \leq \left(\frac{k + p}{2} - \frac{3}{2} \right)^{ \frac{p - 1}{2}} \frac{\Gamma( \frac{k + p}{2})}{\Gamma(\frac{k + p}{2} - \frac{1}{2})}
        \leq \left(\frac{k + p}{2}\right)^{ \frac{p - 1}{2}} \left(\frac{k + p}{2}\right)^{\sfrac{1}{2}}
        = \left(\frac{k + p}{2}\right)^{ \sfrac{p}{2}}
    \end{equation}
    Hence,
    \begin{equation}
        \mathbb{E}^{\sfrac{p}{2}}[X] \leq 2 \left( \frac{k + p}{2} \right) \leq k + p.
    \end{equation}
\end{proof}



\begin{lemma}{Spectral norm moments of non-standard Gaussian random vector}{spectral-norm-moment-vector}
    The matrix $\mtx{A} \in \mathbb{R}^{m \times m}$ and the standard Gaussian random vector $\vct{\omega} \in \mathbb{R}^{m}$ satisfy for all $k,p \in \mathbb{N}$ 
    \begin{equation}
        \mathbb{E}^{\sfrac{p}{2}}\left[ \lVert \mtx{A} \vct{\omega} \rVert _2^2 \right]
        \leq  (k + p) \left( \lVert \mtx{A} \rVert _2^2 + \frac{1}{k} \lVert \mtx{A} \rVert _F^2 \right).
    \end{equation}
    %\begin{equation}
    %    \mathbb{E}^{p}\left[ \lVert \mtx{\Sigma} \mtx{\Omega}_2\rVert _2 \right]
    %    &\leq \sqrt{\frac{k + p}{2}} \cdot \left( 2 + \frac{1}{\sqrt{k}} \right) \cdot \lVert \mtx{\Sigma} \rVert _2 + \sqrt{\frac{k + p}{2k}} \cdot \lVert \mtx{\Sigma} \rVert _F. \notag \\
    %    \mathbb{E}^{p}\left[ \lVert \mtx{\Omega}_1^{\dagger} \rVert _2 \right]
    %    &\leq \frac{1}{2} \left( 1 + \frac{p}{k - r + 1 - p} \right)^{\sfrac{1}{p}} \left( \frac{k + r}{k - r + 2} \right).
    %\end{equation}
    %If we choose 
\end{lemma}

\begin{remark}
    In particular, this result can also be used to bound
    \begin{equation}
        \mathbb{E}^{p}\left[ \lVert \mtx{A} \vct{\omega} \rVert _2 \right] = \sqrt{\mathbb{E}^{\sfrac{p}{2}}\left[ \lVert \mtx{A} \vct{\omega} \rVert _2^2 \right]} \leq \sqrt{k + p} \cdot \left(\lVert \mtx{A} \rVert _2 + \frac{1}{\sqrt{k}}\lVert \mtx{A} \rVert _F\right)
    \end{equation}
    for any $k,p \in \mathbb{N}$.
\end{remark}

\begin{proof}
    With the singular value decomposition $\mtx{A} = \mtx{U} \mtx{\Sigma} \mtx{V}^{\top}$ and the unitary invariance of the spectral norm, it can be seen that $\lVert \mtx{A} \mtx{\omega} \rVert _2^2 = \lVert \mtx{\Sigma} \widetilde{\mtx{\omega}} \rVert _2^2$ where $\widetilde{\mtx{\omega}}$ is again a standard Gaussian random vector. Hence, it is enough to bound $\mathbb{E}^{\sfrac{p}{2}}\left[ \lVert \mtx{\Sigma} \mtx{\omega} \rVert _2^2 \right]$ for a diagonal matrix $\mtx{\Sigma} = \operatorname{diag}(\sigma_1, \dots, \sigma_m)$ with $\sigma_1 \geq \dots \geq \sigma_m \geq 0$.

    First, we can rewrite
    \begin{equation}
        \mathbb{E}^{\sfrac{p}{2}}\left[ \lVert \mtx{\Sigma} \vct{\omega} \rVert _2^2 \right]
        = \mathbb{E}^{\sfrac{p}{2}}\left[ \sum_{i=1}^{m} \sigma_i^2 \omega_i^2 \right].
        \label{equ:matvec-spectral-norm-simplification}
    \end{equation}
    Inspired by the proof of \cite[Theorem 1]{cohen-2016-optimal-approximate}, we split the diagonal entries of $\mtx{\Sigma}$ into $\ell = \lceil m/k \rceil$ groups of size $k \geq 1$
    \begin{equation}
        \overbrace{\underbrace{\sigma_1, \dots, \sigma_k}_{\leq \sigma_1}}^{\geq \sigma_{k+1}}, \overbrace{\underbrace{\sigma_{k+1}, \dots, \sigma_{2k}}_{\leq \sigma_{k+1}}}^{\geq \sigma_{2k+1}}, \dots, \overbrace{\underbrace{\sigma_{(\ell - 1)k + 1}, \dots, \sigma_{\ell k}}_{\leq \sigma_{(\ell - 1)k + 1}}}^{\geq 0}.
    \end{equation}
    If $m$ is not a multiple of $k$, we let $\sigma_i = 0$ for $i > m$. Since $\sigma_1 \geq \dots \geq \sigma_{\ell k} \geq 0$,
    \begin{equation}
        \sigma_1^2 = \lVert \mtx{\Sigma} \rVert _2^2
        \quad \text{and} \quad
        \sigma_{(i-1)k + 1}^2 \leq \frac{1}{k} \sum_{j=1}^{k} \sigma_{(i-2)k + j}^2, i = 2, \dots, \ell,
    \end{equation}
    and therefore
    \begin{equation}
        \sum_{i=1}^{\ell} \sigma_{(i-1)k + 1}^2 = \lVert \mtx{\Sigma} \rVert _2^2 + \sum_{i=2}^{\ell} \sigma_{(i-1)k + 1}^2  \leq \lVert \mtx{\Sigma} \rVert _2^2 + \frac{1}{k} \sum_{n=1}^{(\ell - 1)k} \sigma_n^2 \leq \lVert \mtx{\Sigma} \rVert _2^2 + \frac{1}{k} \lVert \mtx{\Sigma} \rVert _F^2.
        \label{equ:singular-value-group-bound}
    \end{equation}
    This allows us to bound
    \begin{align}
        \mathbb{E}^{\sfrac{p}{2}}\left[ \sum_{i=1}^{m} \sigma_i^2 \omega_i^2 \right]
        &= \mathbb{E}^{\sfrac{p}{2}}\Bigg[ \sum_{i=1}^{\ell} \sum_{j=1}^{k} \underbrace{\sigma_{(i-1)k + j}^2}_{\leq \sigma_{(i-1)k + 1}^2} \omega_{(i-1)k + j}^2 \Bigg] && \text{(separate sum into groups)} \notag \\
        &\leq \mathbb{E}^{\sfrac{p}{2}}\left[ \sum_{i=1}^{\ell} \sigma_{(i-1)k + 1}^2 \sum_{j=1}^{k} \omega_{(i-1)k + j}^2 \right] && \text{($\sigma_{(i-1)k + j}^2 \leq \sigma_{(i-1)k + 1}^2$, $\forall i, j$)} \notag \\
        &\leq \sum_{i=1}^{\ell} \sigma_{(i-1)k + 1}^2 ~ \mathbb{E}^{\sfrac{p}{2}}\left[ \sum_{j=1}^{k} \omega_{(i-1)k + j}^2 \right] && \text{(triangle inequality)} \notag \\
        %&\leq \left( \lVert \mtx{\Sigma} \rVert _2^2 + \frac{1}{k} \lVert \mtx{\Sigma} \rVert _F^2 \right) 2 \left( \frac{\Gamma(\frac{k}{2} + p)}{\Gamma(\frac{k}{2})} \right)^{\sfrac{1}{p}} && \text{(\refequ{equ:singular-value-group-bound} and \cite[Theorem 3.3.2]{hogg-2013-introduction-mathematical})} \notag \\
        &\leq (k + p) \sum_{i=1}^{\ell} \sigma_{(i-1)k + 1}^2 && \text{(\reflem{lem:gamma})} \notag \\
        &\leq (k + p) \left( \lVert \mtx{\Sigma} \rVert _2^2 + \frac{1}{k} \lVert \mtx{\Sigma} \rVert _F^2 \right). && \text{(using \refequ{equ:singular-value-group-bound})}
    \end{align}
    
    %The moments of $\lVert \mtx{\Omega}_1^{\dagger} \rVert _2$ can be bound with help of the proof of \cite[Lemma B.3]{tropp-2023-randomized-algorithms}
    %\begin{align}
    %    \mathbb{E}^{p}\left[ \lVert \mtx{\Omega}_1^{\dagger} \rVert _2 \right]
    %    &= \mathbb{E}\left[ \lVert ( \mtx{\Omega}_1 \mtx{\Omega}_1^{\top} )^{-1} \rVert _2^{\sfrac{p}{2}} \right]^{\sfrac{1}{p}} \notag \\
    %    &\leq \left( 1 + \frac{p}{k - r + 1 - p} \right)^{\sfrac{1}{p}} \left( \frac{1}{\Gamma(k - r + 2)} \right)^{\frac{1}{k - r + 1}} \left( \frac{k + r}{2} \right) \notag \\
    %    &\leq \frac{1}{2} \left( 1 + \frac{p}{k - r + 1 - p} \right)^{\sfrac{1}{p}} \left( \frac{k + r}{k - r + 2} \right)
    %\end{align}
    %With the Taylor series expansion of the exponential function it can be shown that $e^n \geq 1 + n$ and $e^n \geq \frac{n^n}{n!}$ for all $n \in \mathbb{N}$, from which $(n + 1)^{\sfrac{1}{n}} \leq e$ and $\left( \frac{1}{n!} \right)^{\sfrac{1}{n}} \leq \frac{e}{n}$ follow respectively. Hence,
    %\begin{equation}
    %    \mathbb{E}^{k}\left[ \lVert \mtx{\Omega}_1^{\dagger} \rVert _2 \right]
    %    \leq \frac{e^2}{k + 1}\sqrt{ \frac{3k}{2} }
    %    \leq e^2 \sqrt{\frac{3}{2k}}.
    %    \label{equ:OSE-moment-bound-second}
    %\end{equation}

\end{proof}

\begin{lemma}{Spectral norm moments of non-standard Gaussian random matrix}{spectral-norm-moment}
    The matrix $\mtx{A} \in \mathbb{R}^{m \times m}$ and the standard Gaussian random matrix $\mtx{\Omega} \in \mathbb{R}^{m \times k}$ satisfy for all $p \in \mathbb{N}$ 
    \begin{equation}
        \mathbb{E}^{\sfrac{p}{2}}\left[ \lVert \mtx{A} \mtx{\Omega} \rVert _2^2 \right]
        \leq  (k + p) \left( 2 \lVert \mtx{A} \rVert _2^2 + \frac{1}{k} \lVert \mtx{A} \rVert _F^2 \right).
    \end{equation}
    %\begin{equation}
    %    \mathbb{E}^{p}\left[ \lVert \mtx{\Sigma} \mtx{\Omega}_2\rVert _2 \right]
    %    &\leq \sqrt{\frac{k + p}{2}} \cdot \left( 2 + \frac{1}{\sqrt{k}} \right) \cdot \lVert \mtx{\Sigma} \rVert _2 + \sqrt{\frac{k + p}{2k}} \cdot \lVert \mtx{\Sigma} \rVert _F. \notag \\
    %    \mathbb{E}^{p}\left[ \lVert \mtx{\Omega}_1^{\dagger} \rVert _2 \right]
    %    &\leq \frac{1}{2} \left( 1 + \frac{p}{k - r + 1 - p} \right)^{\sfrac{1}{p}} \left( \frac{k + r}{k - r + 2} \right).
    %\end{equation}
    %If we choose 
\end{lemma}

\begin{remark}
    In particular, this result can also be used to bound
    \begin{equation}
        \mathbb{E}^{p}\left[ \lVert \mtx{A} \mtx{\Omega} \rVert _2 \right] = \sqrt{\mathbb{E}^{\sfrac{p}{2}}\left[ \lVert \mtx{A} \mtx{\Omega} \rVert _2^2 \right]} \leq \sqrt{k + p} \cdot \left(\sqrt{2} \lVert \mtx{A} \rVert _2 + \frac{1}{\sqrt{k}}\lVert \mtx{A} \rVert _F\right)
    \end{equation}
    for any $k,p \in \mathbb{N}$. For $p=2$ this bound is slightly less tight than its equivalent in \cite[Lemma B.1]{tropp-2023-randomized-algorithms}.
\end{remark}

\begin{proof}
    In the proof of \cite[Lemma B.1]{tropp-2023-randomized-algorithms}, it is shown that Slepian's inequality \cite[Theorem 7.2.1]{vershynin-2018-highdimensional-probability} applied to two appropriately constructed Gaussian random fields yields
    \begin{equation}
        \mathbb{E}^{\sfrac{p}{2}}\left[ \lVert \mtx{A} \mtx{\Omega} \rVert _2^2 \right]
        \leq \lVert \mtx{A} \rVert _2^2 \mathbb{E}^{\sfrac{p}{2}}\left[ \lVert \vct{\omega}_1 \rVert _2^2 \right] + \mathbb{E}^{\sfrac{p}{2}}\left[ \lVert \mtx{A} \vct{\omega}_2 \rVert _2^2 \right]
    \end{equation}
    for independent standard Gaussian random vectors $\vct{\omega}_1 \in \mathbb{R}^{k}$ and $\vct{\omega}_2 \in \mathbb{R}^{m}$. \textcolor{red}{Doesn't A.1 give a tighter bound for the first term?} \textcolor{green}{Yes. Fixed it.} The first moment can be bound using \reflem{lem:gamma} and the second using \reflem{lem:spectral-norm-moment-vector} to get
    \begin{align}
        \mathbb{E}^{\sfrac{p}{2}}\left[ \lVert \mtx{A} \mtx{\Omega} \rVert _2^2 \right]
        &\leq \lVert \mtx{A} \rVert _2^2 (k + p)  + (k + p) \left( \lVert \mtx{A} \rVert _2^2 + \frac{1}{k} \lVert \mtx{A} \rVert _F^2 \right) \notag \\
        &\leq (k + p) \left( 2 \lVert \mtx{A} \rVert _2^2 + \frac{1}{k} \lVert \mtx{A} \rVert _F^2 \right).
    \end{align}

    %The moments of $\lVert \mtx{\Omega}_1^{\dagger} \rVert _2$ can be bound with help of the proof of \cite[Lemma B.3]{tropp-2023-randomized-algorithms}
    %\begin{align}
    %    \mathbb{E}^{p}\left[ \lVert \mtx{\Omega}_1^{\dagger} \rVert _2 \right]
    %    &= \mathbb{E}\left[ \lVert ( \mtx{\Omega}_1 \mtx{\Omega}_1^{\top} )^{-1} \rVert _2^{\sfrac{p}{2}} \right]^{\sfrac{1}{p}} \notag \\
    %    &\leq \left( 1 + \frac{p}{k - r + 1 - p} \right)^{\sfrac{1}{p}} \left( \frac{1}{\Gamma(k - r + 2)} \right)^{\frac{1}{k - r + 1}} \left( \frac{k + r}{2} \right) \notag \\
    %    &\leq \frac{1}{2} \left( 1 + \frac{p}{k - r + 1 - p} \right)^{\sfrac{1}{p}} \left( \frac{k + r}{k - r + 2} \right)
    %\end{align}
    %With the Taylor series expansion of the exponential function it can be shown that $e^n \geq 1 + n$ and $e^n \geq \frac{n^n}{n!}$ for all $n \in \mathbb{N}$, from which $(n + 1)^{\sfrac{1}{n}} \leq e$ and $\left( \frac{1}{n!} \right)^{\sfrac{1}{n}} \leq \frac{e}{n}$ follow respectively. Hence,
    %\begin{equation}
    %    \mathbb{E}^{k}\left[ \lVert \mtx{\Omega}_1^{\dagger} \rVert _2 \right]
    %    \leq \frac{e^2}{k + 1}\sqrt{ \frac{3k}{2} }
    %    \leq e^2 \sqrt{\frac{3}{2k}}.
    %    \label{equ:OSE-moment-bound-second}
    %\end{equation}

\end{proof}


\end{document}
