
\section{Numerical experiments}
\label{sec:results}

\subsection{Spectral density for Hamiltonian of electronic structure}
\label{subsec:hamiltonian}

Our first numerical example comes from electronic structure interaction \cite{lin-2017-randomized-estimation}, more precisely from the second order finite difference discretization of the Hamiltonian
\begin{equation}
    \mathcal{H} = - \Delta + V
    \label{equ:5-experiments-electronic-hamiltonian}
\end{equation}
in three dimensions. The potential $V$ interacting with the electrons is generated by Gaussian wells
\begin{equation}
    v(r) = v_0 e^{-\lambda r^2}
    \label{equ:5-experiments-gaussian-cell}
\end{equation}
with $v_0 = -4$ and $\lambda = 8$, centered in cells of side length $L=6$ which are stacked $n_c \in \mathbb{N}$ times in each spatial dimension (cf. \reffig{fig:gaussian-well}). The discretization step is fixed to be $h=0.6$, such that the size of the matrix grows cubically with $n_c$. This is an idealized model for the interaction of nuclei on a regular grid with electrons for a $k$-vector in the center of the first Brillouin zone. The distribution of the eigenvalues of the Hamiltonian -- its spectral density -- allows us to interpret the system's energy levels.

\begin{figure}[ht]
    \begin{subfigure}[b]{0.32\columnwidth}
        \input{plots/gaussian-well-1.pgf}
        \caption{$n_c=1$}
        \label{fig:gaussian-well-1}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\columnwidth}
        \input{plots/gaussian-well-2.pgf}
        \caption{$n_c=2$}
        \label{fig:gaussian-well-2}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\columnwidth}
        \input{plots/gaussian-well-5.pgf}
        \caption{$n_c=5$}
        \label{fig:gaussian-well-5}
    \end{subfigure}
    \caption{Cross-sections of the periodic Gaussian well potential $V$ for different sizes $n_c$ of the supercell.}
    \label{fig:gaussian-well}
\end{figure}

While theoretically an important tool, we waive using the non-negative Chebyshev expansion, since the slight indefiniteness of $g_{\sigma}^{(m)}(t \mtx{I}_n - \mtx{A})$ \refequ{equ:matrix-expansion} does not make a difference in finite precision arithmetic. We approximate the integrals for computing the $L^1$-errors in \refsec{sec:analysis} using a midpoint quadrature with $n_t \in \mathbb{N}$ nodes. For a fixed total number of random vectors $n_{\mtx{\Psi}} + n_{\mtx{\Omega}}$, we analyze the convergence behavior of the Chebyshev-Nyström++ method when run on the $1000 \times 1000$ matrix resulting from the finite difference discretization of the Hamiltonian for $n_c = 1$ described above (see \reffig{fig:convergence}). 

\begin{figure}[ht]
    \centering
    \input{plots/convergence.pgf}
    \caption{For increasing values of $n_{\mtx{\Psi}} + n_{\mtx{\Omega}}$ but fixed $m$ we plot the $L^1$-approximation error for $\sigma=0.005$ on the model problem with $n_c = 1$. The $L^1$-error is approximated by a quadrature with $n_t = 100$ evenly spaced nodes.}
    \label{fig:convergence}
\end{figure}

Indeed, we observe that for $n_{\mtx{\Omega}} = 0$, we require $n_{\mtx{\Psi}} = \mathcal{O}(\varepsilon^{-2})$ to achieve an error of order $\varepsilon$, as shown in \refthm{thm:hutchinson}. Because the eigenvalues of the matrix are quite uniformly distributed, we observe the stronger convergence of the Nyström approximation discussed in the end of \refsec{sec:application} once $n_{\mtx{\Omega}}$ exceeds the numerical rank \refequ{equ:gaussian-kernel-numerical-rank-uniform}, which in this case would be somewhat larger than $30$.

\begin{figure}[ht]
    \centering
    \input{plots/distribution.pgf}
    \caption{The Chebyshev-Nyström++ method for different ways of allocations a total of $n_{\mtx{\Psi}} + n_{\mtx{\Omega}}=80$ random vectors to either the Nystr\"om low-rank approximation or the Girard-Hutchinson trace estimation for the Gaussian smoothing kernel with multiple different values of the smoothing parameter. We make the approximation error made in the Chebyshev expansion negligible by rescaling $m=16 / \sigma$ (based on \refthm{thm:chebyshev-error}).}
    \label{fig:distribution}
\end{figure}

\subsection{Spectral density of Hessian matrix of neural network}
\label{subsec:hessian}

\todo{Hessian spectrum analysis?}

\subsection{Trace of parameter-dependent matrix functions}
\label{subsec:function-trace}

\todo{Comparison plots with other estimators (Krylov-Aware)?}
